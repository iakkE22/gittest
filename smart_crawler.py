import time
import hashlib
import json
import os
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import argparse

class SmartXiaohongshuCrawler:
    def __init__(self, headless=False, output_dir="output", wait_login=True):
        self.output_dir = output_dir
        self.wait_login = wait_login
        self.global_post_counter = 0
        if not os.path.exists(output_dir):
            os.makedirs(output_dir)
        
        # è®¾ç½®Chromeé€‰é¡¹
        chrome_options = Options()
        if headless:
            chrome_options.add_argument("--headless")
        chrome_options.add_argument("--no-sandbox")
        chrome_options.add_argument("--disable-dev-shm-usage")
        chrome_options.add_argument("--disable-blink-features=AutomationControlled")
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        chrome_options.add_argument("--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36")
        
        # åˆå§‹åŒ–WebDriver
        self.driver = webdriver.Chrome(options=chrome_options)
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        self.driver.set_window_size(1920, 1080)
        
        print("âœ“ Chromeæµè§ˆå™¨å·²å¯åŠ¨")

    def wait_for_manual_login(self):
        """ç­‰å¾…ç”¨æˆ·æ‰‹åŠ¨ç™»å½•"""
        print("\n" + "="*50)
        print("ğŸ” éœ€è¦ç™»å½•å°çº¢ä¹¦")
        print("è¯·åœ¨æµè§ˆå™¨ä¸­æ‰‹åŠ¨å®Œæˆç™»å½•ï¼Œç„¶åæŒ‰å›è½¦é”®ç»§ç»­...")
        print("="*50)
        input("ç™»å½•å®Œæˆåï¼ŒæŒ‰å›è½¦é”®ç»§ç»­...")
        print("âœ“ ç»§ç»­æ‰§è¡Œçˆ¬è™«ç¨‹åº")

    def check_login_status(self):
        """æ£€æŸ¥ç™»å½•çŠ¶æ€"""
        print("æ­£åœ¨æ£€æµ‹ç™»å½•çŠ¶æ€...")
        
        # æ£€æŸ¥å¤šä¸ªå¯èƒ½çš„ç™»å½•æ ‡è¯†
        login_indicators = [
            ".avatar",
            ".username", 
            ".user-info",
            "[data-testid='avatar']",
            ".login-avatar"
        ]
        
        for indicator in login_indicators:
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR, indicator)
                if elements and any(elem.is_displayed() for elem in elements):
                    print(f"æ£€æµ‹åˆ°å·²ç™»å½•æ ‡è¯†: {indicator}")
                    return True
            except:
                continue
        
        # æ£€æŸ¥URLæ˜¯å¦åŒ…å«ç™»å½•ç›¸å…³ä¿¡æ¯
        current_url = self.driver.current_url
        if any(keyword in current_url.lower() for keyword in ["login", "signin", "ç™»å½•"]):
            print("å½“å‰é¡µé¢ä¸ºç™»å½•é¡µé¢")
            return False
        
        print("æœªæ£€æµ‹åˆ°æ˜ç¡®çš„ç™»å½•çŠ¶æ€")
        return False

    def smart_search_and_collect(self, keyword, target_posts=100):
        """æ™ºèƒ½æœç´¢å’Œæ”¶é›†ç­–ç•¥ - é¿å…å¡ç‰‡ä¸¢å¤±"""
        print(f"ğŸ¯ å¼€å§‹æ™ºèƒ½æœç´¢: '{keyword}'ï¼Œç›®æ ‡å¸–å­æ•°: {target_posts}")
        
        try:
            # è®¿é—®å°çº¢ä¹¦æœç´¢é¡µé¢
            search_url = f"https://www.xiaohongshu.com/search_result?keyword={keyword}&type=51"
            print(f"è®¿é—®æœç´¢é¡µé¢: {search_url}")
            self.driver.get(search_url)
            time.sleep(5)
            
            # æ£€æŸ¥ç™»å½•çŠ¶æ€
            if self.wait_login and not self.check_login_status():
                self.wait_for_manual_login()
            
            # æ”¶é›†æ‰€æœ‰å¸–å­æ•°æ®
            all_posts_data = []
            processed_urls = set()
            scroll_round = 0
            max_scroll_rounds = 20
            
            while len(all_posts_data) < target_posts and scroll_round < max_scroll_rounds:
                scroll_round += 1
                print(f"\nğŸ”„ ç¬¬ {scroll_round} è½®æ”¶é›† (å·²æ”¶é›†: {len(all_posts_data)}/{target_posts})")
                
                # è·å–å½“å‰é¡µé¢çš„æ‰€æœ‰å¡ç‰‡ä¿¡æ¯
                cards_info = self._extract_all_cards_info()
                print(f"å½“å‰é¡µé¢å‘ç° {len(cards_info)} ä¸ªå¡ç‰‡")
                
                # è¿‡æ»¤æ‰å·²å¤„ç†çš„å¡ç‰‡
                new_cards = [card for card in cards_info if card['url'] not in processed_urls]
                print(f"å…¶ä¸­ {len(new_cards)} ä¸ªæ˜¯æ–°å¡ç‰‡")
                
                if not new_cards:
                    print("æ²¡æœ‰å‘ç°æ–°å¡ç‰‡ï¼Œå°è¯•æ»šåŠ¨è·å–æ›´å¤šå†…å®¹...")
                    success = self._smart_scroll_for_more_content()
                    if not success:
                        print("æ»šåŠ¨æœªè·å–åˆ°æ–°å†…å®¹ï¼Œå¯èƒ½å·²åˆ°è¾¾åº•éƒ¨")
                        break
                    continue
                
                # æ‰¹é‡å¤„ç†æ–°å¡ç‰‡
                for card_info in new_cards:
                    if len(all_posts_data) >= target_posts:
                        break
                    
                    print(f"\nğŸ“ å¤„ç†å¡ç‰‡: {card_info['preview'][:50]}...")
                    
                    # è·å–å®Œæ•´å†…å®¹
                    full_content = self._get_full_content_by_url(card_info['url'])
                    if full_content:
                        post_data = {
                            'index': len(all_posts_data) + 1,
                            'url': card_info['url'],
                            'preview': card_info['preview'],
                            'full_content': full_content,
                            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S')
                        }
                        all_posts_data.append(post_data)
                        processed_urls.add(card_info['url'])
                        print(f"âœ… æˆåŠŸæ”¶é›†ç¬¬ {len(all_posts_data)} ä¸ªå¸–å­")
                        
                        # ä¿å­˜è°ƒè¯•ä¿¡æ¯
                        self._save_debug_info(len(all_posts_data), full_content)
                    else:
                        print("âŒ è·å–å®Œæ•´å†…å®¹å¤±è´¥")
                
                # å¦‚æœè¿™è½®æ”¶é›†åˆ°äº†æ–°å†…å®¹ï¼Œç»§ç»­æ»šåŠ¨è·å–æ›´å¤š
                if new_cards:
                    print("æœ¬è½®æ”¶é›†æˆåŠŸï¼Œæ»šåŠ¨è·å–æ›´å¤šå†…å®¹...")
                    self._smart_scroll_for_more_content()
                    time.sleep(2)  # ç­‰å¾…å†…å®¹åŠ è½½
            
            print(f"\nğŸ‰ æ”¶é›†å®Œæˆï¼æ€»å…±è·å– {len(all_posts_data)} ä¸ªå¸–å­")
            
            # ä¿å­˜ç»“æœ
            if all_posts_data:
                self._save_results(all_posts_data, keyword)
                return [post['full_content'] for post in all_posts_data]
            else:
                print("æœªæ”¶é›†åˆ°ä»»ä½•å¸–å­å†…å®¹")
                return []
                
        except Exception as e:
            print(f"æœç´¢è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}")
            return []

    def _extract_all_cards_info(self):
        """æå–å½“å‰é¡µé¢æ‰€æœ‰å¡ç‰‡çš„åŸºæœ¬ä¿¡æ¯"""
        cards_info = []
        
        # å°è¯•å¤šç§å¡ç‰‡é€‰æ‹©å™¨
        selectors = [
            "section.note-item",
            ".note-item", 
            ".feed-item",
            ".search-item"
        ]
        
        cards = []
        for selector in selectors:
            cards = self.driver.find_elements(By.CSS_SELECTOR, selector)
            if cards:
                print(f"ä½¿ç”¨é€‰æ‹©å™¨ {selector} æ‰¾åˆ° {len(cards)} ä¸ªå¡ç‰‡")
                break
        
        if not cards:
            print("æœªæ‰¾åˆ°ä»»ä½•å¡ç‰‡")
            return []
        
        for i, card in enumerate(cards):
            try:
                # è·å–å¡ç‰‡é¢„è§ˆæ–‡æœ¬
                preview_text = card.text.strip()
                if not preview_text:
                    continue
                
                # è·å–å¡ç‰‡é“¾æ¥
                card_url = self._extract_card_url(card)
                if not card_url:
                    continue
                
                cards_info.append({
                    'index': i + 1,
                    'url': card_url,
                    'preview': preview_text[:200],  # åªä¿ç•™å‰200å­—ç¬¦ä½œä¸ºé¢„è§ˆ
                    'element_id': f"card_{i}"
                })
                
            except Exception as e:
                print(f"æå–å¡ç‰‡ {i+1} ä¿¡æ¯å¤±è´¥: {e}")
                continue
        
        return cards_info

    def _extract_card_url(self, card_element):
        """ä»å¡ç‰‡å…ƒç´ ä¸­æå–URL"""
        try:
            # å°è¯•å¤šç§æ–¹æ³•è·å–é“¾æ¥
            methods = [
                lambda: card_element.find_element(By.TAG_NAME, "a").get_attribute("href"),
                lambda: card_element.get_attribute("href"),
                lambda: card_element.find_element(By.CSS_SELECTOR, "[href]").get_attribute("href")
            ]
            
            for method in methods:
                try:
                    url = method()
                    if url and "xiaohongshu.com" in url:
                        return url
                except:
                    continue
            
            return None
            
        except Exception as e:
            return None

    def _get_full_content_by_url(self, post_url):
        """é€šè¿‡URLè·å–å¸–å­çš„å®Œæ•´å†…å®¹"""
        try:
            # åœ¨æ–°æ ‡ç­¾é¡µæ‰“å¼€
            self.driver.execute_script("window.open('');")
            self.driver.switch_to.window(self.driver.window_handles[-1])
            
            print(f"è®¿é—®å¸–å­: {post_url}")
            self.driver.get(post_url)
            time.sleep(3)
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•
            if self.wait_login and not self.check_login_status():
                print("å¸–å­é¡µé¢éœ€è¦ç™»å½•")
                self.wait_for_manual_login()
            
            # æå–å†…å®¹
            content = self._extract_post_content()
            
            # å…³é—­å½“å‰æ ‡ç­¾é¡µï¼Œè¿”å›ä¸»é¡µé¢
            self.driver.close()
            self.driver.switch_to.window(self.driver.window_handles[0])
            
            return content
            
        except Exception as e:
            print(f"è·å–å¸–å­å†…å®¹å¤±è´¥: {e}")
            # ç¡®ä¿è¿”å›ä¸»é¡µé¢
            try:
                if len(self.driver.window_handles) > 1:
                    self.driver.close()
                    self.driver.switch_to.window(self.driver.window_handles[0])
            except:
                pass
            return None

    def _extract_post_content(self):
        """ä»å½“å‰é¡µé¢æå–å¸–å­å†…å®¹"""
        content_selectors = [
            ".note-content",
            ".content",
            ".note-detail", 
            ".desc",
            ".note-text",
            ".post-content",
            "[class*='content']",
            "[class*='desc']"
        ]
        
        for selector in content_selectors:
            try:
                elements = self.driver.find_elements(By.CSS_SELECTOR, selector)
                for element in elements:
                    text = element.text.strip()
                    if text and len(text) > 20:  # è¿‡æ»¤å¤ªçŸ­çš„æ–‡æœ¬
                        print(f"ä½¿ç”¨é€‰æ‹©å™¨ {selector} è·å–åˆ°æ–‡æœ¬")
                        return text
            except:
                continue
        
        # å¦‚æœä¸Šè¿°æ–¹æ³•éƒ½å¤±è´¥ï¼Œå°è¯•è·å–é¡µé¢ä¸»è¦æ–‡æœ¬
        try:
            body_text = self.driver.find_element(By.TAG_NAME, "body").text
            # ç®€å•è¿‡æ»¤ï¼Œæå–å¯èƒ½çš„å†…å®¹éƒ¨åˆ†
            lines = body_text.split('\n')
            content_lines = [line.strip() for line in lines if len(line.strip()) > 10]
            if content_lines:
                return '\n'.join(content_lines[:20])  # å–å‰20è¡Œ
        except:
            pass
        
        return None

    def _smart_scroll_for_more_content(self):
        """æ™ºèƒ½æ»šåŠ¨è·å–æ›´å¤šå†…å®¹"""
        try:
            # è®°å½•æ»šåŠ¨å‰çŠ¶æ€
            initial_height = self.driver.execute_script("return document.body.scrollHeight")
            initial_cards = self.driver.find_elements(By.CSS_SELECTOR, "section.note-item")
            initial_count = len(initial_cards)
            
            print(f"æ»šåŠ¨å‰: é¡µé¢é«˜åº¦={initial_height}px, å¡ç‰‡æ•°={initial_count}")
            
            # æ¸è¿›å¼æ»šåŠ¨ç­–ç•¥
            scroll_steps = [
                ("å°å¹…æ»šåŠ¨", "window.scrollBy(0, 800);", 2),
                ("ä¸­å¹…æ»šåŠ¨", "window.scrollBy(0, 1200);", 3),
                ("æ»šåŠ¨åˆ°åº•éƒ¨", "window.scrollTo(0, document.body.scrollHeight);", 4),
                ("å›æ»šä¸€ç‚¹", "window.scrollBy(0, -400);", 2),
            ]
            
            for step_name, script, wait_time in scroll_steps:
                print(f"æ‰§è¡Œ: {step_name}")
                self.driver.execute_script(script)
                time.sleep(wait_time)
                
                # æ£€æŸ¥æ˜¯å¦æœ‰æ–°å†…å®¹
                current_height = self.driver.execute_script("return document.body.scrollHeight")
                current_cards = self.driver.find_elements(By.CSS_SELECTOR, "section.note-item")
                current_count = len(current_cards)
                
                height_change = current_height - initial_height
                count_change = current_count - initial_count
                
                print(f"  å˜åŒ–: é«˜åº¦+{height_change}px, å¡ç‰‡{count_change:+d}")
                
                # å¦‚æœæ£€æµ‹åˆ°æ˜¾è‘—å˜åŒ–ï¼Œè¯´æ˜æœ‰æ–°å†…å®¹
                if height_change > 1000:
                    print("âœ… æ£€æµ‹åˆ°æ–°å†…å®¹åŠ è½½")
                    return True
            
            print("âŒ æ»šåŠ¨æœªäº§ç”Ÿæ–°å†…å®¹")
            return False
            
        except Exception as e:
            print(f"æ»šåŠ¨å‡ºé”™: {e}")
            return False

    def _save_debug_info(self, post_index, content):
        """ä¿å­˜è°ƒè¯•ä¿¡æ¯"""
        try:
            debug_file = os.path.join(self.output_dir, f"smart_debug_post_{post_index}.txt")
            with open(debug_file, 'w', encoding='utf-8') as f:
                f.write(f"å¸–å­ {post_index} è°ƒè¯•ä¿¡æ¯\n")
                f.write("="*50 + "\n")
                f.write(f"æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"å†…å®¹é•¿åº¦: {len(content)} å­—ç¬¦\n")
                f.write("="*50 + "\n")
                f.write(content)
            print(f"è°ƒè¯•ä¿¡æ¯å·²ä¿å­˜åˆ° {debug_file}")
        except Exception as e:
            print(f"ä¿å­˜è°ƒè¯•ä¿¡æ¯å¤±è´¥: {e}")

    def _save_results(self, posts_data, keyword):
        """ä¿å­˜æ”¶é›†ç»“æœ"""
        try:
            # ä¿å­˜ä¸ºæ–‡æœ¬æ–‡ä»¶
            text_file = os.path.join(self.output_dir, f"{keyword}_smart_texts.txt")
            with open(text_file, 'w', encoding='utf-8') as f:
                f.write(f"å°çº¢ä¹¦ '{keyword}' æœç´¢ç»“æœ\n")
                f.write("="*50 + "\n")
                f.write(f"æ”¶é›†æ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}\n")
                f.write(f"æ€»å¸–å­æ•°: {len(posts_data)}\n")
                f.write("="*50 + "\n\n")
                
                for post in posts_data:
                    f.write(f"å¸–å­ {post['index']}\n")
                    f.write(f"URL: {post['url']}\n")
                    f.write(f"æ—¶é—´: {post['timestamp']}\n")
                    f.write("-" * 30 + "\n")
                    f.write(post['full_content'])
                    f.write("\n" + "="*50 + "\n\n")
            
            # ä¿å­˜ä¸ºJSONæ–‡ä»¶
            json_file = os.path.join(self.output_dir, f"{keyword}_smart_texts.json")
            with open(json_file, 'w', encoding='utf-8') as f:
                json.dump(posts_data, f, ensure_ascii=False, indent=2)
            
            print(f"âœ… ç»“æœå·²ä¿å­˜:")
            print(f"   æ–‡æœ¬æ–‡ä»¶: {text_file}")
            print(f"   JSONæ–‡ä»¶: {json_file}")
            
        except Exception as e:
            print(f"ä¿å­˜ç»“æœå¤±è´¥: {e}")

    def close(self):
        """å…³é—­æµè§ˆå™¨"""
        try:
            self.driver.quit()
            print("âœ“ æµè§ˆå™¨å·²å…³é—­")
        except:
            pass

def main():
    parser = argparse.ArgumentParser(description='æ™ºèƒ½å°çº¢ä¹¦çˆ¬è™« - é¿å…å¡ç‰‡ä¸¢å¤±')
    parser.add_argument('--keyword', type=str, required=True, help='æœç´¢å…³é”®è¯')
    parser.add_argument('--num_posts', type=int, default=100, help='ç›®æ ‡å¸–å­æ•°é‡')
    parser.add_argument('--headless', action='store_true', help='æ— å¤´æ¨¡å¼è¿è¡Œ')
    
    args = parser.parse_args()
    
    crawler = SmartXiaohongshuCrawler(headless=args.headless)
    
    try:
        texts = crawler.smart_search_and_collect(args.keyword, args.num_posts)
        print(f"\nğŸ‰ çˆ¬å–å®Œæˆï¼æˆåŠŸè·å– {len(texts)} ä¸ªå¸–å­")
        
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
    finally:
        crawler.close()

if __name__ == "__main__":
    main() 